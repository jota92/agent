# AI Browser Agent 🤖

AIがブラウザを自動操作するローカルエージェントシステム。視覚認識モデルを使用してウェブページを理解し、マウスカーソルを動かして実際にクリックやタイピングを実行します。

## 特徴 ✨

- **🎯 視覚的AI操作**: Qwen2-VL-2B Instruct モデルでスクリーンショットを解析
- **🧭 構造化プランナー**: タスクを細かなサブステップに自動分解し、"Googleを開く → ボックスをクリック → 入力 → Enter → 結果を選択" のように順番を厳守
- **👁️ 常時モニタリング**: DOM 完了待機 + 画面ハッシュ監視でスタックを検知し、必要に応じて自動リフレッシュ
- **🖱️ リアルタイムカーソル**: AIが操作する巨大なカーソルをブラウザ上に表示
- **📊 座標グリッド**: 100px間隔のグリッドで正確な座標指定
- **🔄 スムーズアニメーション**: カーソルが滑らかに移動（20ステップ、smoothstep）
- **🛡️ ループ防止とポップアップ対応**: 近接クリック防止、警告ダイアログ自動閉じ、失敗時の強制遷移
- **🎨 ライブストリーミング + プランビューワ**: カーソル軌跡に加えて、左パネルに進行中のプランと達成率を表示

## 必要要件 📋

- Linux または macOS
- Python 3.8+
- ChromeDriver

## セットアップ 🚀

1. **リポジトリをクローン**
```bash
git clone https://github.com/YOUR_USERNAME/agent.git
cd agent
```

2. **クイックスタート**
```bash
chmod +x start.sh
./start.sh
```

このスクリプトが自動的に:
- Python仮想環境のセットアップ
- 依存関係のインストール
- Qwen2-VL-2B Instruct モデルのダウンロード（初回のみ）
- サーバーの起動

3. **ブラウザでアクセス**
```
http://127.0.0.1:5000
```

## 使い方 💡

1. ブラウザで http://127.0.0.1:5000 を開く
2. URLを入力してブラウザを開く
3. タスクを入力（例: "googleで'openai'を検索して最初の結果をクリックしてください"）
4. "Start AI Agent" をクリック
5. 左サイドバーの **Agent Plan** でサブステップの進捗を確認しながら、AI がカーソルを動かして自動操作するのを観察

## 技術スタック 🔧

- **バックエンド**: Flask (Python)
- **ブラウザ制御**: Selenium + Chrome DevTools Protocol
- **AI モデル**: Qwen2-VL-2B Instruct (Transformers)
- **画像処理**: Pillow
- **フロントエンド**: HTML/JavaScript (MJPEG streaming)

## 主な機能 🎨

### AIカーソル
- 80px巨大グロー効果
- 赤いクロスヘア
- スムーズな移動アニメーション

### 座標グリッド
- 黄色の100pxグリッド
- X/Y座標ラベル
- 中心マーカー

### 構造化プランナー
- 指示文から検索キーワードを抽出
- Google系タスクは 5 ステップ定型（Google を開く→クリック→入力→Enter→結果クリック）
- 進行中のステップを UI に表示して失敗ポイントを迅速に把握

### ループ防止システム
1. 完全一致アクション検出
2. 近接座標検出（100px閾値）
3. 強制アクションオーバーライド

### イレギュラー検知
- DOM readyState を監視して操作タイミングを最適化
- 連続スクリーンショットが同一なら自動でページをリロード
- JavaScript alert / confirm / prompt を自動承認して操作を継続

## API エンドポイント 📡

- `GET /` - メインUI
- `GET /stream` - MJPEGビデオストリーム
- `POST /ai/task` - AIタスク開始
- `GET /ai/status/<task_id>` - タスクステータス
- `POST /ai/stop/<task_id>` - タスク停止
- `GET /ai/health` - ヘルスチェック

## 設定 ⚙️

`app.py`で以下をカスタマイズ可能:

```python
VLM_MODEL_ID = "Qwen/Qwen2-VL-2B-Instruct"  # 使用する視覚言語モデル
AI_MAX_STEPS = 30                     # 最大ステップ数
AI_STEP_TIMEOUT = 15                  # タイムアウト（秒）
JPEG_QUALITY = 65                     # ストリーム画質
TARGET_STREAM_WIDTH = 1024            # ストリーム幅
```

## ライセンス 📄

MIT License

## 注意事項 ⚠️

- これは開発サーバーです。本番環境では使用しないでください
- AIの操作は完璧ではありません
- ローカルでのみ動作します（セキュリティ上の理由）

## 貢献 🤝

プルリクエスト歓迎！

## 作者 👨‍💻

Created with ❤️ using AI assistance
